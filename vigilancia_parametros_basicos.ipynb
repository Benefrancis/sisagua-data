{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-24T01:26:59.741286400Z",
     "start_time": "2023-12-24T01:26:30.015451200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: distributed in c:\\users\\francis\\appdata\\roaming\\python\\python311\\site-packages (2023.12.1)\n",
      "Requirement already satisfied: click>=8.0 in c:\\users\\francis\\appdata\\roaming\\python\\python311\\site-packages (from distributed) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (2.2.1)\n",
      "Requirement already satisfied: dask==2023.12.1 in c:\\users\\francis\\appdata\\roaming\\python\\python311\\site-packages (from distributed) (2023.12.1)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (3.1.2)\n",
      "Requirement already satisfied: locket>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (1.0.0)\n",
      "Requirement already satisfied: msgpack>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (1.0.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (23.1)\n",
      "Requirement already satisfied: psutil>=5.7.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (5.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (6.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (2.4.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (1.7.0)\n",
      "Requirement already satisfied: toolz>=0.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (0.12.0)\n",
      "Requirement already satisfied: tornado>=6.0.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (6.3.2)\n",
      "Requirement already satisfied: urllib3>=1.24.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (1.26.16)\n",
      "Requirement already satisfied: zict>=3.0.0 in c:\\users\\francis\\appdata\\roaming\\python\\python311\\site-packages (from distributed) (3.0.0)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask==2023.12.1->distributed) (2023.4.0)\n",
      "Requirement already satisfied: partd>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask==2023.12.1->distributed) (1.4.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask==2023.12.1->distributed) (6.0.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click>=8.0->distributed) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2>=2.10.3->distributed) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.13.0->dask==2023.12.1->distributed) (3.11.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mariadb in c:\\users\\francis\\appdata\\roaming\\python\\python311\\site-packages (1.1.9)\n",
      "Requirement already satisfied: SQLAlchemy in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.39)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from mariadb) (23.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from SQLAlchemy) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: dask in c:\\users\\francis\\appdata\\roaming\\python\\python311\\site-packages (2023.12.1)\n",
      "Requirement already satisfied: click>=8.1 in c:\\users\\francis\\appdata\\roaming\\python\\python311\\site-packages (from dask) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask) (2.2.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask) (2023.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask) (23.1)\n",
      "Requirement already satisfied: partd>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask) (1.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask) (6.0)\n",
      "Requirement already satisfied: toolz>=0.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask) (0.12.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask) (6.0.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click>=8.1->dask) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.13.0->dask) (3.11.0)\n",
      "Requirement already satisfied: locket in c:\\programdata\\anaconda3\\lib\\site-packages (from partd>=1.2.0->dask) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade distributed\n",
    "%pip install mariadb SQLAlchemy\n",
    "%pip install --upgrade dask"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import required modules\n",
    "import urllib \n",
    "from urllib import parse\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, inspect, text\n",
    "import dask.dataframe as dd\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T01:26:59.741286400Z",
     "start_time": "2023-12-24T01:26:59.739270200Z"
    }
   },
   "id": "46ba4e356384742c",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def sql_df(q):\n",
    "  with engine.connect() as conexao:\n",
    "    consulta = conexao.execute(text(q))\n",
    "    dados = consulta.fetchall()\n",
    "  return pd.DataFrame(dados,columns=consulta.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T01:26:59.751645200Z",
     "start_time": "2023-12-24T01:26:59.746286200Z"
    }
   },
   "id": "91a5a5e1d145871c",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Codificar a senha\n",
    "senha_codificada = urllib.parse.quote(\"root\")\n",
    "\n",
    "# Criar a URL de conexão\n",
    "url_conexao = f\"mariadb+mariadbconnector://root:{senha_codificada}@127.0.0.1:3306/python-sisagua\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T01:26:59.775557400Z",
     "start_time": "2023-12-24T01:26:59.754360400Z"
    }
   },
   "id": "2d1308b6f5395f1e",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Criar o objeto da engine\n",
    "engine = create_engine(url_conexao, pool_recycle=3600)  # 1 hora de tempo de reciclagem"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T01:26:59.776556500Z",
     "start_time": "2023-12-24T01:26:59.760884100Z"
    }
   },
   "id": "d1c5239f1693d519",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pontos_de_captacao', 'vigilancia_parametros_basicos_2014', 'vigilancia_parametros_basicos_2023']\n"
     ]
    }
   ],
   "source": [
    "inspector = inspect(engine)\n",
    "print(inspector.get_table_names())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T01:26:59.821283600Z",
     "start_time": "2023-12-24T01:26:59.768560200Z"
    }
   },
   "id": "ac6fffa17e8baf2b",
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformando os dados em arquivo parquet\n",
    "\n",
    "Ao ler o arquivo Parquet, o Dask automaticamente cria um DataFrame Dask particionado para suportar operações paralelas. O número de partições dependerá de como o arquivo Parquet foi particionado originalmente. O Dask tenta ler cada parte em uma partição separada sempre que possível.\n",
    "\n",
    "Depois de ler o arquivo Parquet para um DataFrame Dask, você pode realizar operações distribuídas em seus dados de forma semelhante a como faria com um DataFrame pandas.\n",
    "\n",
    "Gravando e depois lendo os dados do arquivo .parquet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4756554be743f99"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Atenção são mais de 2.000.000 de registros em cada tabela\n",
    "for tabela in inspector.get_table_names(): \n",
    "    \n",
    "    query = f'SELECT * FROM {tabela}'\n",
    "    print(query)\n",
    "    \n",
    "    df = sql_df(query)\n",
    "    # Criar um DataFrame Dask a partir do DataFrame Pandas\n",
    "    df_dask = dd.from_pandas(df, npartitions=16)  # Você pode ajustar o número de partições conforme necessário\n",
    "    \n",
    "    caminho_arquivo = f'data/{tabela}/{tabela}'\n",
    "    \n",
    "    arquivo = f'{caminho_arquivo}.parquet' \n",
    "    \n",
    "    if not os.path.exists(caminho_arquivo): \n",
    "        os.makedirs(caminho_arquivo)\n",
    "    \n",
    "    # Salvar o DataFrame Dask no formato Parquet\n",
    "    df_dask.to_parquet(\n",
    "        arquivo,\n",
    "        # write_options={'compression': 'gzip'},\n",
    "        engine='pyarrow',  # ou 'fastparquet', dependendo da sua preferência\n",
    "        overwrite=True\n",
    "    )\n",
    "\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T01:31:07.635411800Z",
     "start_time": "2023-12-24T01:26:59.820277800Z"
    }
   },
   "id": "f5f9efe47efdeacc",
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fef7d6c3e092881"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for tabela in inspector.get_table_names(): \n",
    "    caminho_arquivo = f'data/{tabela}/{tabela}'\n",
    "    \n",
    "    arquivo = f'{caminho_arquivo}.parquet'\n",
    "    \n",
    "    # Ler o arquivo Parquet para um DataFrame Dask\n",
    "    df_dask_lido = dd.read_parquet(arquivo)\n",
    "    # Visualizar as primeiras linhas do DataFrame Dask lido\n",
    "    df_dask_lido.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T01:48:19.238893600Z",
     "start_time": "2023-12-24T01:48:18.314316800Z"
    }
   },
   "id": "76a4b1579f9c90e9",
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
